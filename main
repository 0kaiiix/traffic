# Filename: simple_qa_streamlit.py

import os
import datetime
from dotenv import load_dotenv
import openai
import streamlit as st

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

def init_environment():
    load_dotenv(override=True)
    openai.api_key = os.getenv("OPENAI_API_KEY")
    return openai.api_key

def init_llm(openai_key):
    return ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_key)

def save_output(question, answer, output_path="./output"):
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(output_path, f"qa_result_{timestamp}.txt")
    with open(filename, "w", encoding="utf-8") as f:
        f.write("[Question]\n" + question + "\n\n")
        f.write("[Answer]\n" + answer + "\n")
    return filename

def main():
    st.set_page_config(page_title="ğŸ¤– æ³•è¦å•ç­”ç³»çµ±", layout="wide")
    st.title("ğŸ¤– æ³•è¦çŸ¥è­˜ç°¡æ˜“å•ç­”ç³»çµ±")
    st.markdown("è«‹è¼¸å…¥èˆ‡è»Šè¼›æ³•è¦ç›¸é—œçš„å•é¡Œï¼Œç³»çµ±æœƒä½¿ç”¨ GPT å›ç­”ã€‚")

    openai_key = init_environment()
    llm = init_llm(openai_key)

    query = st.text_area("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼ˆç¹é«”ä¸­æ–‡ï¼‰:", "é…’å¾Œé–‹è»Šç½°å¤šå°‘éŒ¢ï¼Ÿ", height=100)

    if st.button("ğŸš€ æŸ¥è©¢"):
        with st.spinner("æ­£åœ¨æŸ¥è©¢ä¸­..."):
            response = llm.invoke([HumanMessage(content=query)])
            st.success("âœ… å›ç­”å®Œæˆï¼")
            st.subheader("ğŸ”¹ å›ç­”å…§å®¹")
            st.write(response.content)

            filename = save_output(query, response.content)
            st.download_button("ğŸ’¾ ä¸‹è¼‰çµæœæª”æ¡ˆ", data=open(filename, "r", encoding="utf-8").read(), file_name=os.path.basename(filename))

if __name__ == "__main__":
    main()
